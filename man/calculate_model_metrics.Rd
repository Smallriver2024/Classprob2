% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calculate_model_metrics.R
\name{calculate_model_metrics}
\alias{calculate_model_metrics}
\title{Calculate Classification Model Performance Metrics}
\usage{
calculate_model_metrics(
  predicted_probs,
  true_labels,
  cutoff = 0.5,
  n_bootstrap = 1000
)
}
\arguments{
\item{predicted_probs}{A numeric vector of predicted probabilities.}

\item{true_labels}{A factor or numeric vector of true labels (0 and 1).}

\item{cutoff}{A numeric value or "kappa" (default: 0.5). If "kappa", the optimal
cutoff based on Kappa is used.}

\item{n_bootstrap}{Number of bootstrap samples (default: 1000).}
}
\value{
A list containing the metrics, their 95% confidence intervals, and the cutoff value(s).
}
\description{
This function calculates various performance metrics for a classification model,
including AUC, sensitivity, specificity, NPV, PPV, and accuracy. It also computes
95% confidence intervals for these metrics using bootstrap methods. The cutoff
for classification can be set manually or optimized based on Kappa.
}
